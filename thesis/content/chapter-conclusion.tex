% !TEX root = ../main.tex
% chktex-file 46
\chapter{Zusammenfassung}%
\label{sec:conclusion}

Abschließend wird nun zusammengefasst, inwiefern das in~\ref{sec:intro:goals} beschriebene Ziel einer erweiterbaren, parallelisierbaren Wissensgraph-Konstruktion aus Kommunikationsdaten erreicht wurde.
Hierfür werden in~\ref{sec:conclusion:review} die erreichten Teilziele betrachtet.
Anschließend wird in~\ref{sec:conclusion:todo} ein Ausblick auf Möglichkeiten der Weiterentwicklung des Systems gegeben.

\section{Rückblick}%
\label{sec:conclusion:review}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.65\textwidth]{gfx/conclusion/overview.pdf}
	\caption{Grober Aufbau des Konstruktionsverfahrens}\label{fig:conclusion:overview}
\end{figure}
In Kapitel~\ref{sec:text2kg} wurden Lösungen für die drei wesentlichen Teilprobleme Ontologie, Sprachverarbeitung und Grapherweiterung beschrieben.
Die drei Teillösungen bilden zusammen ein Konstruktionsverfahren, welches dem zu Anfang beschriebenen Aufbau entspricht.

\paragraph{Ontologie}
Die Wissensgraphontologie basiert auf Konzeptgraphen.
Im Gegensatz zu den Fakten-Tripel basierten semantischen Netzen, die lediglich beschreiben, welche Beziehungen zwischen Konzepten existieren, kann mittels Konzeptgraphen auch beschrieben werden, welche Beziehungen nicht, oder nur möglicherweise existieren.
Die konstruierten Wissensgraphen haben also eine deutlich höhere Ausdrucksstärke, als z.~B. NELL oder der Google~Knowledge~Graph.
Diese Ausdrucksstärke ist notwendig, um die Komplexität natürlichsprachlicher Aussagen sinnvoll abbilden zu können.

Damit die Konzeptgraphen eine möglichst präzise Semantik haben, muss die Semantik der verwendeten Relationen beschrieben werden.
Es wurde daher ein möglichst minimales Set von Relationen definiert~\tref{sec:text2kg:ontology:pred}, welches zur Beschreibung einer Vielzahl natürlichsprachlicher Aussagen geeignet ist.

Eine der in~\ref{sec:intro:goals} beschriebenen Anforderungen an das Konstruktionsverfahren ist die Erweiterbarkeit, d.~h.\ die prinzipielle Möglichkeit nicht natürlichsprachliche Eingaben einzufügen.
Konkret bedeutet dies, dass z.~B. ein Bild in denselben Wissensgraph eingefügt werden kann, in den auch Textnachrichten eingefügt werden.
Da die gewählten Konzeptgraph-Relationen nicht speziell für natürliche Sprache ausgelegt sind, ist dies prinzipiell möglich;
es gibt keine Relationen, die bestimmte grammatikalische Konstrukte oder Wortarten abbilden.
Wie die Integration anderer Eingabearten im Detail aussehen könnte, war jedoch nicht Teil der Aufgabenstellung und wurde daher nicht näher untersucht.

\paragraph{Sprachverarbeitung}
Für die Transformation einer Nachricht in einen Konzeptgraphen wird das Stanford~CoreNLP Framework mit einer Menge von Transformationsregeln~\tref{sec:text2kg:nlp:transform} kombiniert, welche die von CoreNLP gefundenen Strukturen auf äquivalente Konzeptgraph-Strukturen abbilden.

\paragraph{Grapherweiterung}
Das Einfügen des aus einer Nachricht extrahierten Konzeptgraphen in einen bestehenden Wissensgraphen erfolgt mittels PSL.\@
Im Rahmen dieser Arbeit wurde PSL erstmals im Kontext einer Konzeptgraph-basierten Wissensgraph-Konstruktion eingesetzt.
Es wurde ein Set von PSL-Regeln~\tref{sec:text2kg:psl:inference} vorgestellt, welches den Einsatz in diesem Kontext exemplarisch aufzeigt.

Neben der Erweiterbarkeit war auch die Parallelisierbarkeit eines der in~\ref{sec:intro:goals} beschriebenen Ziele.
Durch die Wahl von PSL für die Grapherweiterung wurde diese Anforderung prinzipiell erfüllt.
Das für die Inferenz verwendete ADMM-Verfahren lässt sich gut verteilt lösen.
In~\cite[Kapitel 10]{Boyd2011} wird beschrieben, wie sich ADMM mit verteilten Programmiermodellen, wie z.~B. Map-Reduce oder Pregel, implementieren lässt.
Aufbauend darauf, wird in~\cite{Lubell-Doughtie2013} eine konkrete Map-Reduce-basierte Implementation vorgestellt.
PSL ist prinzipiell also für den Einsatz in Cluster-Umgebungen geeignet.
In der im Rahmen dieser Arbeit erstellten Implementation wurde jedoch die Single-Machine ADMM-Implementation der PSL-Referenzimplementation verwendet, da diese für einen Prototypen völlig ausreichend ist.

Das Ziel ein erweiterbares, parallelisierbares Wissensgraph-Konstruktionsverfahren für Kommunikationsdaten zu konzipieren wurde somit prinzipiell erreicht.
Nichts desto trotz gibt es noch zahlreiche Möglichkeiten das vorgestellte Verfahren weiterzuentwickeln.

\section{Ausblick}%
\label{sec:conclusion:todo}

Im Folgenden wird ein Überblick über Möglichkeiten der Weiterentwickung und offen gebliebene Fragestellungen gegeben.

\paragraph{Verbessern der Testmethode}
Ein Problem bei der Konzeption des Verfahrens war der Umstand, dass es keine Testdaten mit Referenzergebnissen gibt, anhand derer Änderungen am Verfahren bewertet werden können.
Die Qualität vieler Entscheidungen, wie z.~B. der Wahl der Regelgewichte, konnte daher nur auf Basis manuell durchgeführter, stichprobenartiger Tests bewertet werden.

Das Entwickeln eines Testdaten-Sets, mit dem sich die Performance eines Wissensgraph-Konstruktionsverfahrens repräsentativ empirisch messen lässt, ist wichtig, um ein systematisches Weiterentwickeln des Verfahrens zu ermöglichen.
Das in dieser Arbeit verwendete Enron E-Mail Datenset ist potentiell ein guter Ausgangspunkt hierfür.
Zu klären ist, welche Art von Informationen die Referenzergebnisse enthalten und wie eine umfangreiche Menge solcher Referenzergebnisse konstruiert werden kann.

\paragraph{NLP-Phase}
Im vorgestellten Verfahren wird lediglich ein Teil der von CoreNLP extrahierten Informationen in Konzeptgraph-Strukturen übersetzt.
Durch die Integration bislang ungenutzter Abhängigkeitstypen ließe sich die Qualität der Ergebnisse, wie in~\ref{sec:evaluation:quality:results}~Anfrage~2 gezeigt, deutlich verbessern.

Außerdem sollte die verwendete Heuristik zur Übersetzung von natürlichsprachlicher Negation in negative Kontexte verbessert werden.
In~\ref{sec:evaluation:quality:results}~Anfrage~4 wird dies deutlich.
Ein Ansatz hierfür ist z.~B. das Nutzen des CoreNLP Natural Logic Annotators~\cite{MacCartney2007}, welcher u.~a.\ Quantoren, Negationen und die zugehörigen Scopes, d.~h.\ die modifizierten Token, erkennt.

\paragraph{PSL-Phase}
Die verwendeten domänenspezifischen Regeln und das domänenspezifische Vorwissen sind bislang sehr rudimentär.
In künftigen Arbeiten könnten vorhandene Wissensbasen, wie z.~B. NELL~\cite{Carlson2010} oder YAGO~\cite{YAGO}, in die PSL-Inferenz integriert werden.

Neben der Nutzung domänenspezifischen Wissens, besteht außerdem Verbesserungspotential bei der Nutzung von Kontexten in der Inferenz.
Bislang werden Kontexte nur benutzt, um die Richtung von $inst$-Relationen zu ermitteln.
Das Inferieren des $actual$-Attributs von Möglichkeitskontexten~\tref{sec:text2kg:ontology:modal} zur Bestimmung der Glaubwürdigkeit von Aussagen wäre z.~B. eine sinnvolle Erweiterung des Verfahrens.

\paragraph{Inferenz}
Wie~\treft{sec:evaluation:time} gezeigt hat, besteht noch Verbesserungsbedarf bei der Geschwindigkeit der PSL-Inferenz, bevor das Verfahren in der Praxis einsetzbar ist.
Um dies zu erreichen, ist die Kombination verschiedener Ansätze denkbar:
\begin{enumerate}
	\item Nutzen einer Cluster-fähigen ADMM-Implementation, statt der PSL-Referenz\-implementation.
		Hierfür könnte z.~B. die zuvor erwähnte Hadoop Map-Reduce Implementation~\cite{Lubell-Doughtie2013} verwendet werden.
	\item Weiterentwicklung von BOCI, sodass wachsende Eingabemengen unterstützt werden.
		Bereits im ursprünglichen Paper~\cite[Abschnitt 6]{Pujara2015} wird dies als offene Fragestellung für folgende Arbeiten genannt.
		Mittels des Inferenz-Budgets könnte dann die Inferenzdauer nahezu beliebig verringert werden, sofern dafür eine entsprechende Verschlechterung der Inferenzqualität hingenommen wird.
\end{enumerate}
