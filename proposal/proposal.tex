\documentclass[11pt, a4paper]{scrreprt}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[light]{roboto}
\usepackage[all]{nowidow}
\usepackage{graphicx, curves, float, rotating}
\usepackage[usenames, dvipsnames, svgnames, table]{xcolor}
\usepackage{mathtools}

% Page margins:
\usepackage[
	top=25mm,
	bottom=30mm,
	left=25mm,
	right=25mm
]{geometry}

% Colors:
\definecolor{blau}{HTML}{355FB3}
\definecolor{rot}{HTML}{B33535}
\definecolor{gruen}{HTML}{3BB335}

% Fonts:
\renewcommand{\rmdefault}{ppl}
\addtokomafont{subject}{\sffamily\mdseries}
\addtokomafont{title}{\usekomafont{subject}\color{blau}}
\addtokomafont{author}{\usekomafont{subject}}
\addtokomafont{date}{\usekomafont{subject}\normalsize}
\addtokomafont{publishers}{\usekomafont{subject}}
\addtokomafont{titlehead}{\raggedleft\sffamily\mdseries\small\textit}

\addtokomafont{pagenumber}{\sffamily\mdseries}

\addtokomafont{section}{\usekomafont{title}}

% Remove chapter numbers from section numbering:
\renewcommand*\thesection{\arabic{section}}

% Disable paragraph indent:
\setlength{\parindent}{0pt}

\begin{document}

\frontmatter
\titlehead{Entwurf 1}
\subject{Bachelorarbeit Proposal}
\title{
	Probabilistische online\\
	Wissensgraphkonstruktion\\
	aus natürlicher Sprache
}
\author{
	Clemens Damke\\[1ex]
	Matrikelnr. 7011488
}
\publishers{
	{\normalsize betreut von}\\[2ex]
	Prof.~Dr.~Eyke Hüllermeier\\
	Intelligente Systeme\\
	Institut für Informatik\\
	Universität Paderborn
}
\maketitle

\section{Motivation und Hintergrund}

In den letzten Jahren hat die Repräsentation von Wissensbasen durch Graphen immer mehr an Bedeutung gewonnen.
Google benutzt solche sog.\ Wissensgraphen z.~B. zum Beantworten von komplexen Suchanfragen.\\

Die Grundidee dabei ist, Entitäten durch Knoten und Relationen durch Kanten abzubilden.
Entitäten können konkrete Dinge, wie z.~B. Personen, aber auch abstrakte Konzepte, wie z.~B. historische Epochen, sein.
Relationen beschreiben beliebige Beziehungen zwischen den Entitäten, z.~B. $Person(\text{Da~Vinci}) \xrightarrow{\text{lebte~in}} Epoche(\text{Renaissance})$.\\

Da solche Graphen in zahlreichen Domänen einsetzbar sind, wird deren automatisierte Konstruktion bereits seit Jahren erforscht.
Manuelles Konstruieren und vor allem anschließendes Warten und Aktualisieren von Wissensgraphen ist aufgrund der abzubildenden Datenmengen nicht praktikabel.
Bei einer maschinellen automatisierten Konstruktion sind insbesondere zwei Anforderungen problematisch:
\begin{enumerate}
	\item Das Verarbeiten von unstrukturierten Eingaben, wie z.~B. natürlichsprachlichen Texten.
	\item Effizientes Eingliedern neuer Informationen in einen bestehenden Wissensgraphen.
		Dieses Eingliedern von Informationen umfasst im Speziellen:
		\begin{enumerate}
			\item \textbf{Entity Resolution:}
				Hinzukommende Entitäten, die bereits im Graphen enthalten sind, müssen als Duplikate erkannt werden.
				Dies ist i.~d.~R. nicht trivial, da die selbe Entität durch viele verschiedene, oftmals vom Kontext abhängige, Token repräsentiert werden kann;
				z.~B. \textit{Bob} vs. \textit{Robert} oder \textit{Der Papst} vs. \textit{Franziskus}.
			\item \textbf{Link Prediction:}
				Hinzukommende Entitäten müssen mit bereits bestehenden Entitäten in Relation gesetzt werden.
				Hinzukommende Relationen können zudem benutzt werden um andere Relationen zu inferieren;
				z.~B. $$Weiblich(A) \land B \xrightarrow{\text{Sohn~von}} A \implies A \xrightarrow{\text{Mutter~von}} B$$
		\end{enumerate}
\end{enumerate}

Die Kombination dieser beiden Anforderungen ist interessant, da das meiste verfügbare Wissen in natürlichsprachlicher Textform vorliegt und zudem permanent neues Wissen entsteht.
Ein automatisiertes Wissensgraphkonstruktionsverfahren sollte daher beide Anforderungen berücksichtigen.\\

Neben diesen Anforderungen bzgl.\ der Extraktion von Wissen ist zudem wichtig, wie genau der Graph repräsentiert wird.
Zusätzlich zu Knoten bzw.\ Entitäten und Kanten bzw.\ Relationen sind oftmals weitere Metadaten relevant.
Dazu zählt insbesondere die Inferernzkonfidenz des Link Predictors.
Da natürlichsprachliche Eingabeinformationen häufig unvollständig oder fehlerhaft sind, ist es für die Interpretation und Analyse des resultierenden Graphen hilfreich jeder Relation eine Konfidenz $\in [0, 1]$ zuzuordnen.
Das Ergebnis ist ein sog.\ probabilistischer Wissensgraph.

\section{Ziele der Arbeit}

Das beschriebene Problem der online Wissensgraphkonstruktion aus natürlicher Sprache soll im Kontext von textueller Kommunikation zwischen Menschen näher untersucht werden.
Gegeben sei ein Stream von Textnachrichten, denen jeweils ein Inhalt, ein Absender, eine Menge von Empfängern und ggf.\ weitere Metadaten, wie z.~B. Absendezeit, Absendeort oder IP-Adresse, zugeordnet ist.
Ziel ist es ein skalierbares Verfahren zu entwickeln, welches aus diesem Nachrichtenstrom einen Wissensgraph konstruiert.
Insbesondere folgende Informationen sollen im resultierenden Graphen abgebildet werden:
\begin{enumerate}
	\item Jede Nachricht ist eine Entität und soll mit allen zugehörigen Attributen als Knoten eingefügt werden.
	\item Jede Person, die eine Nachricht sendet, empfängt oder darin vorkommt, soll als Entität erkannt werden.
		Personen-Entitäten, die durch eine Entity Resolution mit einer gewissen Konfidenz als identisch erkannt werden, sollen durch eine entsprechend konfidente Äquivalenzkante in Relation gesetzt werden.
	\item Neben Personen sollen auch Orte, die in Nachrichten vorkommen, erkannt werden.
		Idealerweise werden erkannten Orten zudem Geokoordinaten zugeordnet.
	\item Jeder Kante soll, sofern sinnvoll und möglich, ein Zeitpunkt oder Zeitraum zugeordnet werden.
		So kann z.~B. die Anwesenheit einer Person an einem Ort temporal einsortiert werden.
\end{enumerate}

Das gesuchte Verfahren soll zudem erweiterbar sein.
Es sollen Schnittstellen eingeplant werden, um neben dem Textextraktor auch andere Extraktoren, z.~B. für Bilder und Audioaufnahmen, hinzufügen zu können.
Außerdem sollen die Entity Resolution und Link Prediction Verfahren um domänenspezifische Expertensysteme erweiterbar sein.
Ein Beispiel hierfür ist die Geokoordinatenzuordnung zu extrahierten Ortsnamen.
Durch das Erweitern der Link Prediction, kann diese Zuordnung mithilfe eines entsprechenden Expertensystems erfolgen.\\

Wie zuvor erwähnt, soll das gesuchte Verfahren skalierbar sein.
Das bedeutet konkret, dass die Laufzeit für das Verarbeiten einer Nachricht idealerweise ausschließlich von der Größe der Nachricht und nicht von der bisherigen Größe des Wissensgraphen abhängt.
Sofern dies nicht möglich ist, soll der Einfluss der Graphgröße auf die Laufzeit soweit wie möglich reduziert werden.
Die Skalierbarkeit des Verfahrens umfasst zudem auch die Eignung für ein massivparalleles Ausführen im Cluster.\\

Im Rahmen der Arbeit soll ein derartiges Verfahren zuerst entworfen und anschließend implementiert werden.
Die Skalierbarkeitsanforderungen sollen hierbei primär im Entwurf des Verfahrens berücksichtigt werden.
Die Parallelisierbarkeit der Implementation ist für diese Arbeit nachrangig.

\section{Verwandte Arbeiten}

\section{Vorläufiges Inhaltsverzeichnis}

\section{Zeitplan}

\end{document}
